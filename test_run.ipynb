{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Expectations initialized successfully.\n"
     ]
    },
    {
     "ename": "DatasourceError",
     "evalue": "Cannot initialize datasource my_datasource, error: The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     89\u001b[0m     initialize_great_expectations()\n\u001b[1;32m---> 90\u001b[0m     etl_pipeline()\n",
      "Cell \u001b[1;32mIn[15], line 79\u001b[0m, in \u001b[0;36metl_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m# Validate the transformed data\u001b[39;00m\n\u001b[0;32m     78\u001b[0m batch_request \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdatasource_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmy_datasource\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata_connector_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmy_data_connector\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata_asset_name\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mwater_stock\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m---> 79\u001b[0m validator \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mget_validator(\n\u001b[0;32m     80\u001b[0m     batch_request\u001b[39m=\u001b[39;49mBatchRequest(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch_request),\n\u001b[0;32m     81\u001b[0m     expectation_suite_name\u001b[39m=\u001b[39;49msuite_name\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m validator\u001b[39m.\u001b[39mvalidate(run_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMyRunName\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[39m# Check the validation status\u001b[39;00m\n",
      "File \u001b[1;32mc:\\data\\vscode_directory\\allure_dashboard\\.venv\\lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:2715\u001b[0m, in \u001b[0;36mAbstractDataContext.get_validator\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2711\u001b[0m         batch_request_list \u001b[39m=\u001b[39m [batch_request]  \u001b[39m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m   2713\u001b[0m     \u001b[39mfor\u001b[39;00m batch_request \u001b[39min\u001b[39;00m batch_request_list:\n\u001b[0;32m   2714\u001b[0m         batch_list\u001b[39m.\u001b[39mextend(\n\u001b[1;32m-> 2715\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch_list(\n\u001b[0;32m   2716\u001b[0m                 datasource_name\u001b[39m=\u001b[39mdatasource_name,\n\u001b[0;32m   2717\u001b[0m                 data_connector_name\u001b[39m=\u001b[39mdata_connector_name,\n\u001b[0;32m   2718\u001b[0m                 data_asset_name\u001b[39m=\u001b[39mdata_asset_name,\n\u001b[0;32m   2719\u001b[0m                 batch_request\u001b[39m=\u001b[39mbatch_request,\n\u001b[0;32m   2720\u001b[0m                 batch_data\u001b[39m=\u001b[39mbatch_data,\n\u001b[0;32m   2721\u001b[0m                 data_connector_query\u001b[39m=\u001b[39mdata_connector_query,\n\u001b[0;32m   2722\u001b[0m                 batch_identifiers\u001b[39m=\u001b[39mbatch_identifiers,\n\u001b[0;32m   2723\u001b[0m                 limit\u001b[39m=\u001b[39mlimit,\n\u001b[0;32m   2724\u001b[0m                 index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   2725\u001b[0m                 custom_filter_function\u001b[39m=\u001b[39mcustom_filter_function,\n\u001b[0;32m   2726\u001b[0m                 sampling_method\u001b[39m=\u001b[39msampling_method,\n\u001b[0;32m   2727\u001b[0m                 sampling_kwargs\u001b[39m=\u001b[39msampling_kwargs,\n\u001b[0;32m   2728\u001b[0m                 splitter_method\u001b[39m=\u001b[39msplitter_method,\n\u001b[0;32m   2729\u001b[0m                 splitter_kwargs\u001b[39m=\u001b[39msplitter_kwargs,\n\u001b[0;32m   2730\u001b[0m                 runtime_parameters\u001b[39m=\u001b[39mruntime_parameters,\n\u001b[0;32m   2731\u001b[0m                 query\u001b[39m=\u001b[39mquery,\n\u001b[0;32m   2732\u001b[0m                 path\u001b[39m=\u001b[39mpath,\n\u001b[0;32m   2733\u001b[0m                 batch_filter_parameters\u001b[39m=\u001b[39mbatch_filter_parameters,\n\u001b[0;32m   2734\u001b[0m                 batch_spec_passthrough\u001b[39m=\u001b[39mbatch_spec_passthrough,\n\u001b[0;32m   2735\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2736\u001b[0m             )\n\u001b[0;32m   2737\u001b[0m         )\n\u001b[0;32m   2739\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_validator_using_batch_list(\n\u001b[0;32m   2740\u001b[0m     expectation_suite\u001b[39m=\u001b[39mexpectation_suite,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2741\u001b[0m     batch_list\u001b[39m=\u001b[39mbatch_list,\n\u001b[0;32m   2742\u001b[0m     include_rendered_content\u001b[39m=\u001b[39minclude_rendered_content,\n\u001b[0;32m   2743\u001b[0m )\n",
      "File \u001b[1;32mc:\\data\\vscode_directory\\allure_dashboard\\.venv\\lib\\site-packages\\great_expectations\\core\\usage_statistics\\usage_statistics.py:260\u001b[0m, in \u001b[0;36musage_statistics_enabled_method.<locals>.usage_statistics_wrapped_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m         args_payload \u001b[39m=\u001b[39m args_payload_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    258\u001b[0m         nested_update(event_payload, args_payload)\n\u001b[1;32m--> 260\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m     message[\u001b[39m\"\u001b[39m\u001b[39msuccess\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\data\\vscode_directory\\allure_dashboard\\.venv\\lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:2884\u001b[0m, in \u001b[0;36mAbstractDataContext.get_batch_list\u001b[1;34m(self, datasource_name, data_connector_name, data_asset_name, batch_request, batch_data, data_connector_query, batch_identifiers, limit, index, custom_filter_function, sampling_method, sampling_kwargs, splitter_method, splitter_kwargs, runtime_parameters, query, path, batch_filter_parameters, batch_spec_passthrough, batch_request_options, **kwargs)\u001b[0m\n\u001b[0;32m   2806\u001b[0m \u001b[39m@public_api\u001b[39m\n\u001b[0;32m   2807\u001b[0m \u001b[39m@usage_statistics_enabled_method\u001b[39m(\n\u001b[0;32m   2808\u001b[0m     event_name\u001b[39m=\u001b[39mUsageStatsEvents\u001b[39m.\u001b[39mDATA_CONTEXT_GET_BATCH_LIST,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2833\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[\u001b[39mdict\u001b[39m],\n\u001b[0;32m   2834\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Batch]:\n\u001b[0;32m   2835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the list of zero or more batches, based on a variety of flexible input types.\u001b[39;00m\n\u001b[0;32m   2836\u001b[0m \n\u001b[0;32m   2837\u001b[0m \u001b[39m    `get_batch_list` is the main user-facing API for getting batches.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2882\u001b[0m \n\u001b[0;32m   2883\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_batch_list(\n\u001b[0;32m   2885\u001b[0m         datasource_name\u001b[39m=\u001b[39mdatasource_name,\n\u001b[0;32m   2886\u001b[0m         data_connector_name\u001b[39m=\u001b[39mdata_connector_name,\n\u001b[0;32m   2887\u001b[0m         data_asset_name\u001b[39m=\u001b[39mdata_asset_name,\n\u001b[0;32m   2888\u001b[0m         batch_request\u001b[39m=\u001b[39mbatch_request,\n\u001b[0;32m   2889\u001b[0m         batch_data\u001b[39m=\u001b[39mbatch_data,\n\u001b[0;32m   2890\u001b[0m         data_connector_query\u001b[39m=\u001b[39mdata_connector_query,\n\u001b[0;32m   2891\u001b[0m         batch_identifiers\u001b[39m=\u001b[39mbatch_identifiers,\n\u001b[0;32m   2892\u001b[0m         limit\u001b[39m=\u001b[39mlimit,\n\u001b[0;32m   2893\u001b[0m         index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   2894\u001b[0m         custom_filter_function\u001b[39m=\u001b[39mcustom_filter_function,\n\u001b[0;32m   2895\u001b[0m         sampling_method\u001b[39m=\u001b[39msampling_method,\n\u001b[0;32m   2896\u001b[0m         sampling_kwargs\u001b[39m=\u001b[39msampling_kwargs,\n\u001b[0;32m   2897\u001b[0m         splitter_method\u001b[39m=\u001b[39msplitter_method,\n\u001b[0;32m   2898\u001b[0m         splitter_kwargs\u001b[39m=\u001b[39msplitter_kwargs,\n\u001b[0;32m   2899\u001b[0m         runtime_parameters\u001b[39m=\u001b[39mruntime_parameters,\n\u001b[0;32m   2900\u001b[0m         query\u001b[39m=\u001b[39mquery,\n\u001b[0;32m   2901\u001b[0m         path\u001b[39m=\u001b[39mpath,\n\u001b[0;32m   2902\u001b[0m         batch_filter_parameters\u001b[39m=\u001b[39mbatch_filter_parameters,\n\u001b[0;32m   2903\u001b[0m         batch_spec_passthrough\u001b[39m=\u001b[39mbatch_spec_passthrough,\n\u001b[0;32m   2904\u001b[0m         batch_request_options\u001b[39m=\u001b[39mbatch_request_options,\n\u001b[0;32m   2905\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2906\u001b[0m     )\n",
      "File \u001b[1;32mc:\\data\\vscode_directory\\allure_dashboard\\.venv\\lib\\site-packages\\great_expectations\\data_context\\data_context\\abstract_data_context.py:2957\u001b[0m, in \u001b[0;36mAbstractDataContext._get_batch_list\u001b[1;34m(self, datasource_name, data_connector_name, data_asset_name, batch_request, batch_data, data_connector_query, batch_identifiers, limit, index, custom_filter_function, sampling_method, sampling_kwargs, splitter_method, splitter_kwargs, runtime_parameters, query, path, batch_filter_parameters, batch_spec_passthrough, batch_request_options, **kwargs)\u001b[0m\n\u001b[0;32m   2955\u001b[0m datasource_name \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mdatasource_name\n\u001b[0;32m   2956\u001b[0m \u001b[39mif\u001b[39;00m datasource_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatasources:\n\u001b[1;32m-> 2957\u001b[0m     \u001b[39mraise\u001b[39;00m gx_exceptions\u001b[39m.\u001b[39mDatasourceError(\n\u001b[0;32m   2958\u001b[0m         datasource_name,\n\u001b[0;32m   2959\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe given datasource could not be retrieved from the DataContext; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2960\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mplease confirm that your configuration is accurate.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2961\u001b[0m     )\n\u001b[0;32m   2963\u001b[0m datasource \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatasources[\n\u001b[0;32m   2964\u001b[0m     datasource_name\n\u001b[0;32m   2965\u001b[0m ]  \u001b[39m# this can return one of three datasource types, including Fluent datasource types\u001b[39;00m\n\u001b[0;32m   2966\u001b[0m \u001b[39mreturn\u001b[39;00m datasource\u001b[39m.\u001b[39mget_batch_list_from_batch_request(batch_request\u001b[39m=\u001b[39mresult)\n",
      "\u001b[1;31mDatasourceError\u001b[0m: Cannot initialize datasource my_datasource, error: The given datasource could not be retrieved from the DataContext; please confirm that your configuration is accurate."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import great_expectations as ge\n",
    "from great_expectations.dataset import PandasDataset\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def initialize_great_expectations():\n",
    "    try:\n",
    "        subprocess.run([\"great_expectations\", \"init\"], check=True, text=True, input=\"y\")\n",
    "        print(\"Great Expectations initialized successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error initializing Great Expectations:\", e)\n",
    "\n",
    "def create_validation_suite(context, suite_name):\n",
    "    context.add_or_update_expectation_suite(expectation_suite_name=suite_name) \n",
    "\n",
    "# Extract data from a source (e.g., CSV file)\n",
    "def extract_data():\n",
    "    df = pd.read_csv('data.csv')\n",
    "    return df\n",
    "\n",
    "# Transform data\n",
    "def transform_data(data):\n",
    "    # Perform data transformation operations\n",
    "    transformed_data = data.dropna()\n",
    "    return transformed_data\n",
    "\n",
    "# Load data to a destination (e.g., a database)\n",
    "def load_data(data):\n",
    "    # Establish a connection to the SQLite database\n",
    "    conn = sqlite3.connect('database.db')\n",
    "\n",
    "    # Create a database table (if it doesn't exist)\n",
    "    create_table_query = '''\n",
    "    CREATE TABLE IF NOT EXISTS water_stock (\n",
    "    region TEXT,\n",
    "    variable TEXT,\n",
    "    RID INTEGER,\n",
    "    yq REAL,\n",
    "    value INTEGER,\n",
    "    year INTEGER,\n",
    "    Series TEXT,\n",
    "    Unit TEXT,\n",
    "    Source TEXT,\n",
    "    Quarter INTEGER\n",
    ")\n",
    "    '''\n",
    "    conn.execute(create_table_query)\n",
    "\n",
    "    # Insert the transformed data into the database\n",
    "    with conn:\n",
    "        data.to_sql('water_stock', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "# Main ETL function\n",
    "def etl_pipeline():\n",
    "    # Step 1: Extract data\n",
    "    extracted_data = extract_data()\n",
    "\n",
    "    # Step 2: Transform data\n",
    "    transformed_data = transform_data(extracted_data)\n",
    "\n",
    "    # Initialize Great Expectations\n",
    "    context = ge.data_context.DataContext()\n",
    "\n",
    "    # Create a PandasDataset from the transformed data\n",
    "    dataset = PandasDataset(transformed_data)\n",
    "\n",
    "    # Define expectations\n",
    "    suite_name = \"my_expectations\"\n",
    "    create_validation_suite(context, suite_name)\n",
    "    \n",
    "    # Validate the transformed data\n",
    "    batch_request = {\"datasource_name\": \"my_datasource\", \"data_connector_name\": \"my_data_connector\", 'data_asset_name': 'water_stock'}\n",
    "    validator = context.get_validator(\n",
    "        batch_request=BatchRequest(**batch_request),\n",
    "        expectation_suite_name=suite_name\n",
    "    )\n",
    "    validator.validate(run_name='MyRunName')\n",
    "\n",
    "    # Check the validation status\n",
    "    assert validator.success, \"Validation failed. Check the data quality.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initialize_great_expectations()\n",
    "    etl_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
